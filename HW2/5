Выводы:
1. Как отличаются результаты с разными параметрами?
- num_beams=1, length_penalty=1.0: это обычный greedy search, текст детерминированный, часто короткий.
- num_beams=4, length_penalty=1.0: больше разнообразия, выше шанс получить более логичную и завершённую последовательность.
- num_beams=4, length_penalty=0.5: поощряет более длинные ответы, текст может быть избыточным.
- num_beams=4, length_penalty=2.0: поощряет короткие ответы, текст может быть слишком кратким.
- num_beams=8, length_penalty=1.0: ещё больше вариантов, выше шанс найти оптимальную последовательность, но выше затраты.

2. Есть ли закономерность при увеличении/уменьшении num_beams и length_penalty?
- Большее num_beams = больше вариантов, выше качество, но медленнее.
- Меньшее length_penalty = длиннее ответы, больше — короче.

3. Помог ли beam search исправить проблемы greedy decoding?
- Да, beam search позволяет находить более вероятные и логичные последовательности, избегая "жадных" локальных максимумов.

4. Для каких задач beam search лучше nucleus sampling?
- Для задач, где важна максимальная правдоподобность и структурированность (перевод, резюме, генерация кода).
