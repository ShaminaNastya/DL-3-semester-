1. Какие получились метрики? Что можно о них сказать?
MRR: 0.7997
Recall@1: 0.6941
Recall@3: 0.8904
Recall@10: 0.9686
Значения значительно выше. Высокий MRR и высокие Recall@k  указывают на то, что E5 лучше понимает семантику запросов (и документов) и ранжирует выше релевантные ответы.

2. Стало ли лучше в сравнении с TF-IDF? Почему?
Да, стало лучше. Модели, основанные на трансформерах, обучаются на огромных корпусах текста для понимания взаимосвязей между словами в различных контекстах. Они генерируют семантические эмбеддинги — векторы чисел, которые захватывают смысл текста.
Основные преимущества E5 перед TF-IDF в этой задаче:
- понимание семантики; 
- учет контекста; 
- обработка Out-of-Vocabulary (OOV);
- понимание структуры предложения.
В результате, когда мы сравниваем эмбеддинги вопроса и документа с помощью косинусной близости, мы фактически измеряем их семантическое сходство. Это делает E5 гораздо более мощным инструментом для задач поиска по смыслу.
